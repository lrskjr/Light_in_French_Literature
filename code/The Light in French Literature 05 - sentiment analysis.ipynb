{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9bc2ac",
   "metadata": {},
   "source": [
    "Sentiment analysis of sentences holding keywords from emotion and technology lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6375537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37ff543d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\lakj\\AppData\\Local\\Temp\\ipykernel_22448\\1638824676.py:13: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  tokenized_sentences = re.split('\\.', text)\n",
      "C:\\Users\\lakj\\AppData\\Local\\anaconda3\\Lib\\site-packages\\afinn\\afinn.py:97: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  self._word_pattern = re.compile('\\w+', flags=re.UNICODE)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m row \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 74\u001b[0m sentiment_dataframe \u001b[38;5;241m=\u001b[39m sentiment_analysis(emo_key_words, tech_key_words)\n\u001b[0;32m     75\u001b[0m sentiment_dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_cat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sentiment_dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : apply_sentiment_cat(x) )\n\u001b[0;32m     77\u001b[0m sentiment_dataframe\n",
      "Cell \u001b[1;32mIn[4], line 56\u001b[0m, in \u001b[0;36msentiment_analysis\u001b[1;34m(word_list1, word_list2)\u001b[0m\n\u001b[0;32m     54\u001b[0m from_word_list_two\u001b[38;5;241m.\u001b[39mappend(word2)\n\u001b[0;32m     55\u001b[0m afinn \u001b[38;5;241m=\u001b[39m Afinn()\n\u001b[1;32m---> 56\u001b[0m sent_score \u001b[38;5;241m=\u001b[39m afinn\u001b[38;5;241m.\u001b[39mscore(\u001b[38;5;28mstr\u001b[39m(sent))\n\u001b[0;32m     57\u001b[0m sentiment_scores\u001b[38;5;241m.\u001b[39mappend(sent_score)\n\u001b[0;32m     58\u001b[0m sentences\u001b[38;5;241m.\u001b[39mappend(sent)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\afinn\\afinn.py:335\u001b[0m, in \u001b[0;36mAfinn.score_with_pattern\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_with_pattern\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Score text based on pattern matching.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    Performs the actual sentiment analysis on a text. It uses a regular\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m     word_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores_with_pattern(text)\n\u001b[0;32m    336\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28msum\u001b[39m(word_scores))\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\afinn\\afinn.py:370\u001b[0m, in \u001b[0;36mAfinn.scores_with_pattern\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# TODO: \":D\" is not matched\u001b[39;00m\n\u001b[0;32m    369\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_all(text)\n\u001b[1;32m--> 370\u001b[0m scores \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "input_dir = Path.cwd() / '../data/csv_files' # input directory\n",
    "df = pd.read_csv(input_dir /'text_data28_09_24.csv', sep='|')\n",
    "\n",
    "\n",
    "# text string input\n",
    "work = 'La Cousine Bette'\n",
    "text = df[df['title'] == work].iloc[0]['clean_text']\n",
    "\n",
    "\n",
    "# split the text in sentences\n",
    "def sent_tokenizer(text):\n",
    "    tokenized_sentences = re.split('\\.', text)\n",
    "    tokenized_sentences = [s.lstrip() for s in tokenized_sentences]\n",
    "    return tokenized_sentences\n",
    "\n",
    "sentence_list = sent_tokenizer(text)\n",
    "\n",
    "\n",
    "#### Read two lists of keywords - technology and emotion keyowrds ####\n",
    "\n",
    "# path to keyword lists directory \n",
    "input_dir = Path.cwd() / '../data/key_word_lists' \n",
    "\n",
    "\n",
    "# get the tech words\n",
    "key_word_file_name = 'technology_list.txt'\n",
    "with open(input_dir / key_word_file_name, 'r', encoding='utf-8-sig') as file:\n",
    "    tech_key_words = file.read().split('\\n')\n",
    "    \n",
    "# get the emo words    \n",
    "key_word_file_name = 'emotion_list.txt'\n",
    "with open(input_dir / key_word_file_name, 'r', encoding='utf-8-sig') as file:\n",
    "    emo_key_words = file.read().split('\\n')\n",
    "    \n",
    "    \n",
    "#####################\n",
    "# add two word lists and run to get a sentiment score\n",
    "####################\n",
    "def sentiment_analysis(word_list1 = emo_key_words, word_list2 = tech_key_words):\n",
    "    \n",
    "    \n",
    "    from_word_list_one = []\n",
    "    from_word_list_two = []\n",
    "    sentiment_scores = []\n",
    "    sentences = []\n",
    "    \n",
    "    for word1 in word_list1:\n",
    "        for sent in sentence_list:\n",
    "            if word1 in sent:\n",
    "                for word2 in word_list2:\n",
    "                    if word2 in sent:\n",
    "                        from_word_list_one.append(word1)\n",
    "                        from_word_list_two.append(word2)\n",
    "                        afinn = Afinn()\n",
    "                        sent_score = afinn.score(str(sent))\n",
    "                        sentiment_scores.append(sent_score)\n",
    "                        sentences.append(sent)\n",
    "    \n",
    "    senti_dataframe = pd.DataFrame({'word1': from_word_list_one, 'word2': from_word_list_two, \n",
    "                                        'sentiment_score': sentiment_scores, 'sentence': sentences})\n",
    "    \n",
    "    return senti_dataframe\n",
    "\n",
    "# add positive, negative, or neutral cetegory\n",
    "def apply_sentiment_cat(row):\n",
    "    if row < 0:\n",
    "        return 'neg'\n",
    "    elif row == 0:\n",
    "        return 'neu'\n",
    "    elif row > 0:\n",
    "        return 'pos'\n",
    "                \n",
    "sentiment_dataframe = sentiment_analysis(emo_key_words, tech_key_words)\n",
    "sentiment_dataframe['sentiment_cat'] = sentiment_dataframe['sentiment_score'].apply(lambda x : apply_sentiment_cat(x) )\n",
    "\n",
    "sentiment_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecaf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
