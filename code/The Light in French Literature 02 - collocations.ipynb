{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78188b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83b706",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path.cwd() / '../data/csv_files' # input directory\n",
    "df = pd.read_csv(input_dir /'text_data28_09_24.csv', sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b288b44-a8f3-4051-832e-1796056e92a6",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfb680-2d8f-428f-a20a-39ff860c3627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stop words list\n",
    "input_dir = Path.cwd() / '../data/stopwords' # input directory\n",
    "with open(input_dir  / 'fr_stopwords.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    stopwords =  f.read()\n",
    "\n",
    "stopword_list = stopwords.split('\\n')\n",
    "\n",
    "def remove_stopwords(text_string, stopword_list):\n",
    "    \n",
    "    tokens = text_string.split(' ')\n",
    "\n",
    "    wo_stopword = [i for i in tokens if i not in stopword_list]\n",
    "    \n",
    "    return ' '.join(wo_stopword)\n",
    "\n",
    "\n",
    "df['clean_text_wo_stopwords'] = df['clean_text'].progress_apply(lambda x : remove_stopwords(x, stopword_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a707bd-2bb2-4a65-b970-0e8a1517b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "# text input\n",
    "clean_text_groupby_year = df.groupby(by='year').agg({'clean_text_wo_stopwords': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "# Read keyword lists\n",
    "input_dir = Path.cwd() / '../data/key_word_lists'\n",
    "with open(input_dir / 'technology_list.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    keywords1 = f.read().split()\n",
    "\n",
    "with open(input_dir / 'emotion_list.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    keywords2 = f.read().split()\n",
    "\n",
    "\n",
    "# Define the 'windows size'\n",
    "# Define the function to process each row\n",
    "def process_text(text_string):\n",
    "    tokens = text_string.split()\n",
    "    window_size = 10\n",
    "    collocates_dict = defaultdict(Counter)\n",
    "    \n",
    "    for i, word in enumerate(tokens):\n",
    "        if word in keywords1:\n",
    "            start = max(0, i - window_size)\n",
    "            end = min(len(tokens), i + window_size + 1)\n",
    "            context = tokens[start:i] + tokens[i+1:end]\n",
    "            filtered_context = [w for w in context if w in keywords2]\n",
    "            collocates_dict[word].update(filtered_context)\n",
    "    \n",
    "    results = []\n",
    "    for term, collocates in collocates_dict.items():\n",
    "        for collocate, count in collocates.items():\n",
    "            results.append({'Term': term, 'Collocate': collocate, 'Count': count})\n",
    "\n",
    "    return results\n",
    "\n",
    "# Apply the function to each row and store the results in a new column\n",
    "clean_text_groupby_year['collocates'] = clean_text_groupby_year['clean_text_wo_stopwords'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8db12c-6dfd-476c-a40d-c23a17bbe050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_dir = Path.cwd() / '../visualisations/collocation_heatmaps'\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in clean_text_groupby_year[['year', 'collocates']].iterrows():\n",
    "    year = row['year']\n",
    "    collocates_data = row['collocates']\n",
    "    \n",
    "    # Convert the collocates data to a DataFrame\n",
    "    df_input = pd.DataFrame(collocates_data)\n",
    "    \n",
    "    # Check if 'Count' column exists\n",
    "    if 'Count' not in df_input.columns:\n",
    "        print(f\"Skipping year {year} due to missing 'Count' column.\")\n",
    "        continue\n",
    "    \n",
    "    # Pivot the DataFrame to create a matrix for the heatmap\n",
    "    heatmap_data = df_input.pivot_table(index='Term', columns='Collocate', values='Count', fill_value=0)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu')\n",
    "    plt.title(f'Heatmap of technological and emotional collocations for year {year}.\\nCollocation window size: 10')\n",
    "    \n",
    "    # Save the heatmap as a JPG file\n",
    "    output_file = output_dir / f'heatmap_{year}.jpg'\n",
    "    plt.savefig(output_file, format='jpg')\n",
    "    \n",
    "    # Show the plot (optional, can be removed if not needed)\n",
    "    plt.show()\n",
    "    \n",
    "    # Close the plot to free up memory\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a73309-0ed9-4867-a135-6ab73abdf9d9",
   "metadata": {},
   "source": [
    "# Visualise the sum of collocated key words vs years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e6a95-cf43-41c5-bf50-25ec556d72bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each row in the DataFrame\n",
    "# Define the output directory\n",
    "output_dir = Path.cwd() / '../visualisations'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "collocate_sum = []\n",
    "for index, row in clean_text_groupby_year[['year', 'collocates']].iterrows():\n",
    "    year = row['year']\n",
    "    collocates_data = row['collocates']\n",
    "    \n",
    "    # Convert the collocates data to a DataFrame\n",
    "    df_input = pd.DataFrame(collocates_data)\n",
    "    \n",
    "    # Check if 'Count' column exists\n",
    "    if 'Count' not in df_input.columns:\n",
    "        collocate_sum.append(0)\n",
    "        continue\n",
    "    \n",
    "    col_sum = df_input['Count'].sum()\n",
    "    collocate_sum.append(col_sum)\n",
    "\n",
    "year_collocate_sum_df = pd.DataFrame({'year': clean_text_groupby_year['year'],\n",
    "                                      'collocate_sum': collocate_sum})\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Plot the data using seaborn lineplot\n",
    "sns.lineplot(x='year', y='collocate_sum', marker='o', data=year_collocate_sum_df)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Sum of collocations of technological and emotional keywords over years. Collocation window size: 10')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Collocate Sum')\n",
    "\n",
    "# Save the plot as a JPG file\n",
    "output_file = output_dir / 'collocate_sum_plot.jpg'\n",
    "plt.savefig(output_file, format='jpg')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecafc198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
